services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 20

  ollama-init:
    image: ollama/ollama:latest
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      OLLAMA_HOST: http://ollama:11434
    entrypoint: ["/bin/sh", "-c", "ollama pull llama3.2:1b && ollama pull nomic-embed-text"]
    volumes:
      - ollama_data:/root/.ollama
    restart: "no"

  backend:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      ollama-init:
        condition: service_completed_successfully
    env_file:
      - ./ollama/backend/.env
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_EXTRACT_MODEL: llama3.2:1b
      OLLAMA_EXTRACT_NUM_PREDICT: 64
      OLLAMA_EMBED_MODEL: nomic-embed-text
      APP_TIMEZONE: America/Argentina/Buenos_Aires
      APP_CURRENCY: ARS
      EXPENSES_DB_PATH: /app/ollama/backend/data/expenses.db
      CHROMA_PERSIST_DIR: /app/ollama/backend/data/chroma
      CHROMA_COLLECTION_NAME: expenses
    volumes:
      - ./ollama:/app/ollama
    command: python -u -m ollama.backend.telegram
    restart: unless-stopped

volumes:
  ollama_data:
